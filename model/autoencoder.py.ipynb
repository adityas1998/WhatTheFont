{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.layers import Conv2D\n",
    " \n",
    "\n",
    "class SCAE(tf.keras.Model):\n",
    "    def __init__():\n",
    "        \n",
    "        self.learning_rate = 0.01\n",
    "        self.optimizer = tf.keras.optimizers.Adam(learning_rate=self.learning_rate)\n",
    "        self.batch_size = 128\n",
    "        self.epoch = 1\n",
    "        \n",
    "        # Conv2D(64, (3, 3), activation='relu', padding='same')\n",
    "        self.conv_layer1 = Conv2D(filters=64, strides=(2,2), activation='relu', padding='same')\n",
    "        self.conv_layer2 = Conv2D(filters=128, stries=(2,2), activation='relu', padding='same')\n",
    "        self.deconv_layer1 = Conv2DTranspose(filters=64, strides=(2,2), activation='relu', padding='same')\n",
    "        self.deconv_layer2 = Conv2DTranspose(filters=1, strides=(2,2), activation='relu', padding='same')\n",
    "        \n",
    "\n",
    "    def call(self, inputs):\n",
    "        c1 = self.conv_layer1(inputs)\n",
    "#         c1 = tf.nn.max_pool(c1, [1, 2, 2 ,1], 2, self.padding) #? idk\n",
    "        c2 = self.conv2_layer2(c1)\n",
    "        \n",
    "        d1 = self.deconv_layer1(d1)\n",
    "        # paper says unpool, we say not now\n",
    "        d2 = self.deconv_layer(d1)\n",
    "        return d2\n",
    "        \n",
    "    def loss(original, decoded):\n",
    "        return tf.reduce_sum((original-decoded)**2) / original.shape[0]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(model, images):\n",
    "    batches = images.shape[0] / model.batch_size\n",
    "    \n",
    "    for i in range(batches):\n",
    "        image_inputs = images[i * model.batch_size : (i+1) * model.batch_size]\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            res = model(image_inputs)\n",
    "            loss = model.loss(image_inputs, res)\n",
    "        \n",
    "        gradient = tape.gradient(loss, model.trainable_variables)\n",
    "        model.optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    \n",
    "\n",
    "main():\n",
    "    \n",
    "    images = preprocess(files)\n",
    "    \n",
    "    model = SCAE()\n",
    "    for i in range(model.epoch):\n",
    "        print(\"---EPOCH\", i, \"---\")\n",
    "        res = train(model, images)\n",
    "        \n",
    "    \n",
    "    \n",
    "if __name__== \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
